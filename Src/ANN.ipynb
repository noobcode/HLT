{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Gensim\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "# to make nbs importable\n",
    "import io, os, sys, types\n",
    "from IPython import get_ipython\n",
    "from nbformat import read\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "#from nbs_import import NotebookLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# custom\n",
    "from analize_text import get_sentenceID\n",
    "from paths import *\n",
    "\n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "from nltk import pos_tag, pos_tag_sents\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "# scikit learn\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "# keras\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from feature_transformer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6832 664 1299\n"
     ]
    }
   ],
   "source": [
    "# read dataframes of sentences and entities\n",
    "\n",
    "# TRAIN SET\n",
    "sentences_df_train = pd.read_csv(SENTENCE_PATH_train)\n",
    "entities_df_train = pd.read_csv(ENTITY_PATH_train)\n",
    "\n",
    "#TEST SET\n",
    "sentences_df_test1 = pd.read_csv(SENTENCE_PATH_test1)\n",
    "entities_df_test1 = pd.read_csv(ENTITY_PATH_test1)\n",
    "\n",
    "#TEST2 SET\n",
    "sentences_df_test2 = pd.read_csv(SENTENCE_PATH_test2)\n",
    "entities_df_test2 = pd.read_csv(ENTITY_PATH_test2)\n",
    "\n",
    "print(len(sentences_df_train), len(sentences_df_test1), len(sentences_df_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset (embeddings_POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(148031, 20) (148031,)\n",
      "(14896, 20) (14896,)\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(ROOT_DIR, 'XY', 'LEMMA_20')\n",
    "X_test2 = np.load(os.path.join(data_path, 'X_test2.npy'))\n",
    "X_test1 = np.load(os.path.join(data_path, 'X_test1.npy'))\n",
    "X_train = np.load(os.path.join(data_path, 'X_train.npy'))\n",
    "\n",
    "Y_test2 = np.load(os.path.join(data_path, 'Y_test2.npy'))\n",
    "Y_test1 = np.load(os.path.join(data_path, 'Y_test1.npy'))\n",
    "Y_train = np.load(os.path.join(data_path, 'Y_train.npy'))\n",
    "\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test1.shape, Y_test1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2vmodel = Word2Vec.load('../word_vectors_stem_20')\n",
    "word_vectors = w2vmodel.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode labels\n",
    "- Convert labels from B-I-O to $0, 1, 2$ for SVM\n",
    "- Convert labels from B-I-O to $[1 0 0, 0 1 0, 0 0 1]$ for ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode class values as integers = B-I-O -> 0-1-2\n",
    "encoder = LabelEncoder()\n",
    "encoded_Y = encoder.fit_transform(Y_train)\n",
    "Y_train = encoded_Y\n",
    "# convert integers to one-hot encoding\n",
    "Y_train_one_hot = np_utils.to_categorical(encoded_Y) # SVM does not need one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "experiment with:\n",
    "- original data\n",
    "- MinMaxScaler\n",
    "- Standardizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#min_max_scaler = MinMaxScaler()\n",
    "#X_train = min_max_scaler.fit_transform(X_train)\n",
    "\n",
    "#standard_scaler = StandardScaler()\n",
    "#X_train = standard_scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train / validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train/validation shapes: (148031, 20) (0, 20)\n",
      "Y train/validation shapes:  (148031, 3) (0, 3)\n"
     ]
    }
   ],
   "source": [
    "train_perc = 1\n",
    "train_size = int(len(X_train) * train_perc)\n",
    "\n",
    "# split train validatioin (NN)\n",
    "X_tr, X_vl = X_train[:train_size,:], X_train[train_size:,:]\n",
    "Y_tr_nn, Y_vl_nn = Y_train_one_hot[:train_size], Y_train_one_hot[train_size:]\n",
    "\n",
    "print (\"X train/validation shapes:\", X_tr.shape, X_vl.shape)\n",
    "print (\"Y train/validation shapes: \", Y_tr_nn.shape, Y_vl_nn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from sklearn import preprocessing\n",
    "from keras.optimizers import *\n",
    "from keras.initializers import *\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 512)               10752     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 142,851\n",
      "Trainable params: 142,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_inputs = X_train.shape[1] # size of a vector\n",
    "num_outputs = 3 # b-i-o tags\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=512, input_shape=(num_inputs,), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(Dense(units=128, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(units=num_outputs, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training callbacks\n",
    "- F1-score\n",
    "- Precision\n",
    "- Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "class Metrics(Callback):\n",
    "\n",
    "    def __init__(self, x_val, y_val):\n",
    "        self.x_val = x_val\n",
    "        self.y_val = y_val\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_f1s_micro = []\n",
    "        self.val_recalls_micro = []\n",
    "        self.val_precisions_micro = []\n",
    "        self.val_f1s_macro = []\n",
    "        self.val_recalls_macro = []\n",
    "        self.val_precisions_macro = []\n",
    "        self.val_f1s_weighted = []\n",
    "        self.val_recalls_weighted = []\n",
    "        self.val_precisions_weighted = []\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_predict = np.argmax((np.asarray(self.model.predict(self.x_val))), axis=1)\n",
    "        val_targ = np.argmax(self.y_val, axis=1)\n",
    "        # micro\n",
    "        f1_micro = f1_score(val_targ, val_predict, average='micro')\n",
    "        recall_micro = recall_score(val_targ, val_predict, average='micro')\n",
    "        precision_micro = precision_score(val_targ, val_predict, average='micro')\n",
    "        # macro\n",
    "        f1_macro = f1_score(val_targ, val_predict, average='macro')\n",
    "        recall_macro = recall_score(val_targ, val_predict, average='macro')\n",
    "        precision_macro = precision_score(val_targ, val_predict, average='macro')\n",
    "        # weighted\n",
    "        f1_weighted = f1_score(val_targ, val_predict, average='weighted')\n",
    "        recall_weighted = recall_score(val_targ, val_predict, average='weighted')\n",
    "        precision_weighted = precision_score(val_targ, val_predict, average='weighted')\n",
    "        \n",
    "        # append metrics to access them later\n",
    "        # micro\n",
    "        self.val_f1s_micro.append(f1_micro)\n",
    "        self.val_recalls_micro.append(recall_micro)\n",
    "        self.val_precisions_micro.append(precision_micro)\n",
    "        # macro\n",
    "        self.val_f1s_macro.append(f1_macro)\n",
    "        self.val_recalls_macro.append(recall_macro)\n",
    "        self.val_precisions_macro.append(precision_macro)\n",
    "        # weighted\n",
    "        self.val_f1s_weighted.append(f1_weighted)\n",
    "        self.val_recalls_weighted.append(recall_weighted)\n",
    "        self.val_precisions_weighted.append(precision_weighted)\n",
    "        \n",
    "        print (\" — val_f1_micro: %.4f — val_precision_micro: %.4f — val_recall_micro: %.4f\" % (f1_micro, precision_micro, recall_micro))\n",
    "        print (\" — val_f1_macro: %.4f — val_precision_macro: %.4f — val_recall_macro: %.4f\" % (f1_macro, precision_macro, recall_macro))\n",
    "        print (\" — val_f1_weighted: %.4f — val_precision_weighted: %.4f — val_recall_weighted: %.4f\" % (f1_micro, precision_micro, recall_micro))\n",
    "        return\n",
    "\n",
    "    \n",
    "metrics_callback = Metrics(x_val=X_vl, y_val=Y_vl_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "148031/148031 [==============================] - 34s 226us/step - loss: 0.2457 - acc: 0.9021\n",
      "Epoch 2/30\n",
      "148031/148031 [==============================] - 34s 231us/step - loss: 0.2254 - acc: 0.9099\n",
      "Epoch 3/30\n",
      "148031/148031 [==============================] - 33s 222us/step - loss: 0.2196 - acc: 0.9111\n",
      "Epoch 4/30\n",
      "148031/148031 [==============================] - 33s 220us/step - loss: 0.2156 - acc: 0.9132\n",
      "Epoch 5/30\n",
      "148031/148031 [==============================] - 34s 232us/step - loss: 0.2128 - acc: 0.9151\n",
      "Epoch 6/30\n",
      "148031/148031 [==============================] - 34s 230us/step - loss: 0.2106 - acc: 0.9157\n",
      "Epoch 7/30\n",
      "148031/148031 [==============================] - 35s 240us/step - loss: 0.2096 - acc: 0.9167\n",
      "Epoch 8/30\n",
      "148031/148031 [==============================] - 33s 223us/step - loss: 0.2080 - acc: 0.9174\n",
      "Epoch 9/30\n",
      "148031/148031 [==============================] - 34s 231us/step - loss: 0.2064 - acc: 0.9178\n",
      "Epoch 10/30\n",
      "148031/148031 [==============================] - 35s 240us/step - loss: 0.2062 - acc: 0.9180\n",
      "Epoch 11/30\n",
      "148031/148031 [==============================] - 37s 252us/step - loss: 0.2050 - acc: 0.9192\n",
      "Epoch 12/30\n",
      "148031/148031 [==============================] - 34s 230us/step - loss: 0.2033 - acc: 0.9193\n",
      "Epoch 13/30\n",
      "148031/148031 [==============================] - 39s 266us/step - loss: 0.2049 - acc: 0.9196\n",
      "Epoch 14/30\n",
      "148031/148031 [==============================] - 33s 223us/step - loss: 0.2025 - acc: 0.9202\n",
      "Epoch 15/30\n",
      "148031/148031 [==============================] - 35s 233us/step - loss: 0.2010 - acc: 0.9203\n",
      "Epoch 16/30\n",
      "148031/148031 [==============================] - 35s 239us/step - loss: 0.2016 - acc: 0.9207\n",
      "Epoch 17/30\n",
      "148031/148031 [==============================] - 35s 237us/step - loss: 0.2008 - acc: 0.9216\n",
      "Epoch 18/30\n",
      "148031/148031 [==============================] - 35s 235us/step - loss: 0.2006 - acc: 0.9222\n",
      "Epoch 19/30\n",
      "148031/148031 [==============================] - 33s 220us/step - loss: 0.1994 - acc: 0.9227\n",
      "Epoch 20/30\n",
      "148031/148031 [==============================] - 32s 216us/step - loss: 0.1997 - acc: 0.9220\n",
      "Epoch 21/30\n",
      "148031/148031 [==============================] - 33s 222us/step - loss: 0.1998 - acc: 0.9222\n",
      "Epoch 22/30\n",
      "148031/148031 [==============================] - 32s 218us/step - loss: 0.1988 - acc: 0.9226\n",
      "Epoch 23/30\n",
      "148031/148031 [==============================] - 32s 219us/step - loss: 0.1987 - acc: 0.9224\n",
      "Epoch 24/30\n",
      "148031/148031 [==============================] - 35s 235us/step - loss: 0.1976 - acc: 0.9232\n",
      "Epoch 25/30\n",
      "148031/148031 [==============================] - 37s 252us/step - loss: 0.1981 - acc: 0.9227\n",
      "Epoch 26/30\n",
      "148031/148031 [==============================] - 36s 246us/step - loss: 0.1975 - acc: 0.9232\n",
      "Epoch 27/30\n",
      "148031/148031 [==============================] - 33s 221us/step - loss: 0.1990 - acc: 0.9234\n",
      "Epoch 28/30\n",
      "148031/148031 [==============================] - 33s 225us/step - loss: 0.1987 - acc: 0.9229\n",
      "Epoch 29/30\n",
      "148031/148031 [==============================] - 37s 247us/step - loss: 0.1953 - acc: 0.9241\n",
      "Epoch 30/30\n",
      "148031/148031 [==============================] - 36s 242us/step - loss: 0.1963 - acc: 0.9243\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "batch_size = 16\n",
    "\n",
    "history = model.fit(X_tr, Y_tr_nn, \n",
    "                    epochs=epochs, \n",
    "                    shuffle=True, verbose=1, \n",
    "                    batch_size=batch_size,\n",
    "                    #validation_data=(X_vl, Y_vl_nn),\n",
    "                    #callbacks=[metrics_callback]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# max micro and macro f1 score obtained\n",
    "f1_micro = metrics_callback.val_f1s_micro\n",
    "f1_macro = metrics_callback.val_f1s_macro\n",
    "\n",
    "print(\"max f1 micro:\", np.round(np.max(f1_micro), 4), \"epoch:\", np.argmax(f1_micro))\n",
    "print(\"max f1 macro:\", np.round(np.max(f1_macro), 4), \"epoch:\", np.argmax(f1_macro))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of Loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-dd8a88ff3d0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'training loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'--'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'validation loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Categorical cross-entropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'best'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_loss'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8W9Wd9/HPz7sd29kcm+z7CqQJ8YRCEqAQCJQhUGhLaZlCB550Wmg7wKSEgRbKdFpIuvA8DG2hLbRlWhgINKRsmZSlQFiCwdkXyAaJsyc4q+P1PH9YdmVbsmVb9pXu/b5fL15IV1fS71rw1dU5555jzjlERCQYUrwuQEREuo9CX0QkQBT6IiIBotAXEQkQhb6ISIAo9EVEAkShLyISIAp9EZEAUeiLiARImtcFNFdQUOCGDRvmdRkiIknlvffe2++c69fWfgkX+sOGDaOkpMTrMkREkoqZfRTLfmreEREJEIW+iEiAKPRFRAJEoS8iEiAKfRGRAEm40Tsdtai0jAVLNrKzvIIBvbKZO2ssl00e6HVZIiIJxRehv6i0jNueXk1FdS0AZeUV3Pb0agAFv4hIGF807yxYsrEx8BtUVNeyYMlGjyoSEUlMvgj9neUV7douIhJUvgj9Ab2y27VdRCSofBH6c2eNJTs9tcm27PRU5s4a61FFIiKJyRcduQ2dtd9duIqq2joGavSOiEhEvgh9qA/+lzbsZfWOcl6d+xmvyxERSUi+CX2AUwbkU1FV43UZIiIJy1eh//WzR/L1s0d6XYaISMLyRUeuiIjExlehv27nYT7zk1d5a/MBr0sREUlIvgr9nIxUtu4/pouyRESi8FXoF+ZnArDnyAmPKxERSUy+Cv2cjDTystLYe7jS61JERBKSr0IfoCg/iz2HdaYvIhKJr4ZsApw3vpDcDN8dlohIXPguHW+7aLzXJYiIJCzfNe8AOOdwznldhohIwvFd6D9Rsp1x33uRT45Xe12KiEjC8V3o52amUVlTp85cEZEIfBf6RQ1j9RX6IiIt+C70C/OyADRWX0QkAv+Fvs70RUSi8l3oZ6al8tUzhjKuf77XpYiIJBzfjdMHuPvSU7wuQUQkIfnuTB/qx+kfOaEhmyIizfky9G97ejUzf/Y3r8sQEUk4vgz9fnmZ7DtSSW2drsoVEQkXU+ib2YVmttHMNpnZvAiP32xm68xslZm9ZGZDwx6rNbMVoX8Wx7P4aArzs6hzcOCohm2KiIRrM/TNLBV4ALgImABcZWYTmu1WChQ75yYCC4H5YY9VOOcmhf6ZHae6W1WU1zBsU6EvIhIuljP9qcAm59wW51wV8DhwafgOzrlXnHPHQ3ffBgbFt8z2Kcqvv0Brt8bqi4g0EUvoDwS2h93fEdoWzXXAC2H3s8ysxMzeNrPLOlBjuw3tm8O3zxvNsL453fF2IiJJI67j9M3saqAYODts81DnXJmZjQBeNrPVzrnNzZ43B5gDMGTIkE7X0Ssng5vPH9Pp1xER8ZtYzvTLgMFh9weFtjVhZjOB24HZzrnGxnTnXFno31uAV4HJzZ/rnHvIOVfsnCvu169fuw4gmoPHqth1qCIuryUi4hexhP67wGgzG25mGcCXgCajcMxsMvAg9YG/N2x7bzPLDN0uAKYB6+JVfGuueXg5tz29ujveSkQkabTZvOOcqzGzG4ElQCrwsHNurZndDZQ45xYDC4Bc4EkzA/g4NFJnPPCgmdVR/wVzj3OuW0K/KD+TsnJ15IqIhIupTd859zzwfLNt3w+7PTPK894ETu1MgR1VmJ9F6cflXry1iEjC8uUVuQBFeVkcOFZFVU2d16WIiCQM/4Z+aF79fboqV0SkkW9Df+rwPvz48lPJzfTl7NEiIh3i20Qc0S+XEf1yvS5DRCSh+PZMv67OsabsENsPHm97ZxGRgPBt6ANc9sAyHlv+sddliIgkDN+GfkqKUZiXqUnXRETC+Db0AYp6ZrFX0yuLiDTyd+jnZbFHZ/oiIo38Hfr5mQp9EZEwvh2yCXDlPwzhnHGFOOcIzQkkIhJovg79CQPymUC+12WIiCQMXzfvHD5RzdJ1e9TEIyIS4uvQ333oBP/nDyUs33rQ61JERBKCr0O/KK9+gXSd6YuI1PN16Odnp5GVnqLQFxEJ8XXomxlF+Vns0QVaIiKAz0MfdIGWiEg4Xw/ZBLhr9slkpvv+u01EJCa+D/0JAzROX0Skge9PgbfuP8ajb22joqrW61JERDzn+9BftaOc7z2zlrLyCq9LERHxnO9DvzA0Vn+vOnNFRPwf+kX5mQDsOaLQFxHxfegX5jdclaux+iIivg/93Mw0cjPTNFZfRIQADNkEePZb0ynIy/S6DBERzwUi9IcV9PC6BBGRhOD75h2A1z/cxy9e3eR1GSIingtE6L+xaT/3Lf0Q55zXpYiIeCoQoV+Ul0VVbR3lx6u9LkVExFPBCP2GYZsaqy8iAReQ0A9doKWx+iIScAEJfU3FICICMYa+mV1oZhvNbJOZzYvw+M1mts7MVpnZS2Y2tNnj+Wa2w8z+K16Ft8fAXtmsvusCPj9lkBdvLyKSMNoMfTNLBR4ALgImAFeZ2YRmu5UCxc65icBCYH6zx/8DeK3z5XZMSoqRl5WOmXlVgohIQojlTH8qsMk5t8U5VwU8DlwavoNz7hXn3PHQ3beBxlNqM5sCFAH/G5+SO+bhN7bym9e3eFmCiIjnYgn9gcD2sPs7QtuiuQ54AcDMUoCfAv/W0QLj5dUP9vGXlTu9LkNExFNxnYbBzK4GioGzQ5u+CTzvnNvRWtOKmc0B5gAMGTIkniU1KsrL5IPdR7rktUVEkkUsoV8GDA67Pyi0rQkzmwncDpztnGsYG3kGMMPMvgnkAhlmdtQ516Qz2Dn3EPAQQHFxcZdcNluUn8W+o5XU1jlSU9S2LyLBFEvovwuMNrPh1If9l4Avh+9gZpOBB4ELnXN7G7Y7574Sts+11Hf2thj90x2K8jOprXMcOFbZuJqWiEjQtNmm75yrAW4ElgDrgSecc2vN7G4zmx3abQH1Z/JPmtkKM1vcZRV3UGF+FrmZaZqKQUQCzRJtErLi4mJXUlIS99d1zmnIpoj4lpm955wrbmu/QFyRCyjwRUQIUOg757jpf1bwZMn2tncWEfGpwIS+mfHGpv2899EnXpciIuKZwIQ+1I/g0QLpIhJkwQr9vCxNrywigRao0C/Mz2KvFlIRkQALVOgPL8ihT48MausSa5iqiEh3ievcO4luzlkjmXPWSK/LEBHxTKDO9EVEgi5Qob/jk+N88cG3eP3DfV6XIiLiiUCFfmZaKsu3HmTr/mNelyIi4olAhX7fHhmkppjG6otIYAUq9FNSjMK8TI3VF5HAClToQ/1iKjrTF5GgCtSQTYDThvSmorrW6zJERDwRuND//iUTvC5BRMQzgWveEREJssCF/isb9jJj/st8fOC416WIiHS7wIV+Wqqx/WAFu9WZKyIBFLjQL8rPAtAIHhEJpOCFfp5CX0SCK3Chn5+dRmZaCnuP6AItEQmewIX+Myt2kppiPPTaFqbd8zKLSsu8LklEpNsEapz+otIybnt6dePFWWXlFdz29GoALps80MvSRES6RaDO9Bcs2djiatyK6loWLNnoUUUiIt0rUKG/s7yiXdtFRPwmUKE/oFd2u7aLiPhNoEJ/7qyxZKenNtmWnmrMnTXWo4pERLpXoDpyGzprFyzZyM7yCtJSjR4Zqcw6+SSPKxMR6R6BCn2oD/6G8H9nywH+6eHllH78CWeOKvC4MhGRrhe40A93+oi+vDnvXApyM70uRUSkWwSqTT+ShsDfuPuIx5WIiHS9wIc+wOPLP+bC//saq3cc8roUEZEupdAHPjuxP31yMviPZ9fhnPO6HBGRLhNT6JvZhWa20cw2mdm8CI/fbGbrzGyVmb1kZkND24ea2ftmtsLM1prZv8T7AOIhPyudmy8Yw/JtB3lxzW6vyxER6TJthr6ZpQIPABcBE4CrzKz5QrOlQLFzbiKwEJgf2r4LOMM5Nwk4HZhnZgPiVXw8XVk8mLFFefzohfWc0MLpIuJTsZzpTwU2Oee2OOeqgMeBS8N3cM694pxrWH/wbWBQaHuVc65hDuPMGN/PE2mpKdzxj+M5XlnL5n1HvS5HRKRLxDJkcyCwPez+DurP2qO5Dnih4Y6ZDQaeA0YBc51zOztQZ7eYMbofr9/6GXIyAj2SVUR8LK5n3mZ2NVAMLGjY5pzbHmr2GQVcY2ZFEZ43x8xKzKxk37598Syp3XIy0qiprePtLQc8rUNEpCvEEvplwOCw+4NC25ows5nA7cDssCadRqEz/DXAjAiPPeScK3bOFffr1y/W2rvMg69t4cu/fpsNuw97XYqISFzFEvrvAqPNbLiZZQBfAhaH72Bmk4EHqQ/8vWHbB5lZduh2b2A6kPCT13/l9CHkZaXzw2fXawiniPhKm43XzrkaM7sRWAKkAg8759aa2d1AiXNuMfXNObnAk2YG8LFzbjYwHvipmTnAgJ8451Z30bHETa+cDG6aOZq7/rKO4h/+lYPHqhjQK5u5s8ZqhS0RSWox9Vg6554Hnm+27ftht2dGed5SYGJnCvRKXlYaBhw4VgVoaUUR8YeEHULptZ8t/ZDmDTtaWlFEkp1CPwotrSgifqTQj0JLK4qIHyn0o4i0tGJGWoqWVhSRpKZLT6NovrRiSorRJyediyf297gyEZGOU+i3InxpxaXr9vB//lDC79/cxvUzRnhcmYhIx6h5J0Yzxxdy7rhCfr70A/YcPuF1OSIiHaLQj5GZceclEzhjZAHVtXVelyMi0iFq3mmHoX178Jtrir0uQ0Skw3Sm3wHbDx7nrsVrdcYvIklHod8BG3cf4XdvbuN3y7Z5XYqISLso9Dtg5oQizhtXyH1//YDdh9SpKyLJQ6HfQXdecjLVdY7/fH6916WIiMRMod9BQ/rm8I2zR/KXlTt5c/N+r8sREYmJRu90wjfOGUl1bR0T+ud7XYqISEwU+p2QlZ7Kdy8cx6LSssbpGrTYiogkMoV+Jy0qLePWp1ZRWVM/fFOLrYhIIlObfictWLKxMfAbaLEVEUlUCv1O0mIrIpJMFPqdpMVWRCSZKPQ7KdJiKykGN58/2qOKRESiU0duJzVfbKV/ryz+9bwxXDFlMM45zMzjCkVE/k6hHwfhi600OHKimjl/eI9rzhzKhadotS0RSQxq3ukiqSlGZU0t33qslNc+2Od1OSIigEK/y+RkpPHI16YyqjCPOY+WULLtoNcliYgo9LtSz+x0Hr1uKgN6ZvO1R95lTdkhr0sSkYBTm34XK8jN5L+vP51vP1ZKVnpqzFM2aGoHEekKCv1uMKBXNk/+yxk8s2Intz29iorq1qdsWFRaxm1Pr6aiurbV/URE2kvNO93EzFiwZGNj4DeoqK7lrsVrG+//4a1t3LFoTWPgh++nqR1EpLMU+t0o2tQM5RXVjbefKNnO0cqadj1fRCRWCv1uFG1qhoG9shpvP/utGQzU1A4i0kUU+t0o0pQN2empzJ01Lsb9xnZ5jSLib+rI7UbNp2yINiqnxdQOPbMYe1IuORmpLV5TRKQ9zDnndQ1NFBcXu5KSEq/LSChVNXVc9sAy9hw+wZKbzqIgN9PrkkQkwZjZe8654rb2i6l5x8wuNLONZrbJzOZFePxmM1tnZqvM7CUzGxraPsnM3jKztaHHrmz/oUhGWgo/v3ISR07UcPufV5NoX9QikjzaDH0zSwUeAC4CJgBXmdmEZruVAsXOuYnAQmB+aPtx4KvOuZOBC4H7zKxXvIoPkrEn5XHLBWNYsnYPfy4t87ocEUlSsZzpTwU2Oee2OOeqgMeBS8N3cM694pw7Hrr7NjAotP0D59yHods7gb1Av3gVHzTXzxjBPwzrzY+e38CJZuP4RURiEUtH7kBge9j9HcDprex/HfBC841mNhXIADZHeGwOMAdgyJAhMZQUTKkpxs++OInKmlqy0tWpKyLtF9chm2Z2NVAMLGi2vT/wKPA151xd8+c55x5yzhU754r79dMPgdYM7pPDqMI8AD46cMzjakQk2cQS+mXA4LD7g0LbmjCzmcDtwGznXGXY9nzgOeB259zbnStXGvz6tS1c8PPX2LT3qNeliEgSiSX03wVGm9lwM8sAvgQsDt/BzCYDD1If+HvDtmcAfwb+4JxbGL+y5dJJA8jOSOWWJ1dSU9vix5OISERthr5zrga4EVgCrAeecM6tNbO7zWx2aLcFQC7wpJmtMLOGL4UvAmcB14a2rzCzSfE/jOApzM/ih5edwsrt5fzy1RbdJBEtKi1j2j0vM3zec0y752UWaRSQSODo4qwk963HSnl25U4K8jLZf6Qy6lW+zadrhvqpHX58+amarlnEB2K9OEvTMCS5M0b04dmVO9l3pL4bpay8grkLV/LC6p0U9czmUEU1544rDE3rHHm6ZoW+SHAo9JPcA69spvlvtepax5J1e+mZnU7P7HROGdAz6rTMmq5ZJFgU+kkuWmgbsPLOCxrv/+7NbZRF2FfTNYsEi6ZWTnLRQrv59kjTNQP88/RhnXp/dQ6LJBeFfpKLde79yyYP5MeXn8rAXtkYcFJ+FpefNpB/nja8w+/d0DlcVl6B4+9r+Sr4RRKXmneSXKxz9DfsG2n7viOVFORmYGbtem91DntrUWlZTJ+7SDiFvg9EC/NYbN53lM89sIxbLxrHV04f2q7nRutPKCuv4K7Fa7l+xnAG9c5p3K6Qip/mQ3AbfmUB+ptKq9S8E3DD+/Zg0pDe/GDxOtaUHYr5eXuPnIi6kldmWgqPv/tx4/2XN+zhhj++x61PrVJTUJy09itLpDUK/YBLSTHuu3ISfXMz+OYf3+dQRXWbz1m1o5zZ9y+jqqaOzLSm/wllp6dy7xUTWXnnBY1n+W9tPsBzq3dTWdN0uoh4hFQQO5IrqmojjsQCDcGVtin0hT49MvivL09mZ3kF3124stWVuRav3MkXfvUWqSnGMzdO594rJjZ2Dg/sld14hW9m2t9/Bdx+8QSi9RZ0JqSSqSM5Xl9Oq3cc4uL7X4/6uIbgSlvUpi8ATBnah3kXjWPdzsNU1dY1Ce0GD7+xlbufXcfUYX34xdWnUZCbyYQB+TG1IQ/olR3x7LR/ryycc+3uRAZYsGRDUnQkx6P9vbbO8au/bebnSz+gX14m3zxnJI8s29bk+FMMbj5/dPwPQDosEfuxdKYvja6bPpyffvFTEQMfYMboAr42bRj/ff3p7V6cPdrQ0lMH5HPNI++y61DsZ/zOOZas3U1Z+YmIjydKE4dzjg27D3P3X9Z2uv39lidWsGDJRmadchIvfucsvnvhuCZDcHvnpFPn4L2Py7WGcoJI1F+imnBNWti09wg3/KmUwxXV7D50gtysNO6efTKfO21Qp1430lnPsaoafvjsetJSjTsvOZkrThsY9ay/4ReBc47LfvEma8oOUVvX8r/fXjnpjCnM4yufHsKFp5xEZlpql5xxRXrNz57an+VbD/LX9XtYum5P1Lb3BndcPJ5/nDiAk3pmRXzNW84fw+VTBrF860G2HzzO5a38fe59cQPpKcZN54/p0C8nia9p97wc8fMf2CubZfPOjfv7xTrhmkJfWrj/pQ/56dIPmmzLTEvh3ismdslP048OHGPuk6tYvu0gM8cXctaYAh7829bG4Pv2uaM4WlXLH9/5iIX/ciZ9emSw61AFb23az+2L1raYOfQLxYN47YN9bDtwnD49Mpg0qCfLNh9o0pHc2gyjsXxBRJu19KzRBSxZt4es9BSmjypg5vgi7vvrh+w+3PJXSXqqUV3ruOX8MXzrvNEsLNnOHc+s4UT13+tMSzF+8oVPxfR3D28mq61zpKYo+L00fN5zLebFgvopUrbec3Hc30+zbEqHPf7u9hbbKmvquqytfGjfHjw259M8smwrC17cwOsf7m8M6LLyCm4NtX9PHd6Hg8eq6NMjg/49s7l8ymBSUlIiBnRdnePNzQf477c/4sW1u1u8Z0V1LT96fj0zRhfQKyejMSAjt7+voraujiumDGbP4RP8ubSM+1/6MGKTzYod5fzmq8VMG1VAdmhIa1Z6atRprScO6kleVjoAP3phfZPAB6ipczH/3RsCf8X2cm76nxX8+qvFjCrMbfsD6GKJ2K7dHQrzM9lzuLLFdq872xX60oIXM3KmphjXzxjBb9/Yyq5DLc+KC3IzeOLrZ7TYHu3CtJQUY/roAqaPLoh6xrX3SCVTfvhXzOCGc0bxb7PGcu+LkTqH67j72fVcMWUw5cerueeFDVGPY+/hSmZOKGpRI7R91fQnxyIPl23v370gN4PDFdVc//t3WXTDNHrlZLTr+fEU5IvIbrtoPN9duIqq2qa/MJtPkdLd1JErLcQ6iVtX2B0h8AEOHK3q8GtGq7t3Tjo/mH0y3z53NFOH92n1/Q+Hrl8Y2a8Hq++6gIHt/BtdNnkgy+ady9Z7LmbZvHMjBl68/u6Deufw4D9NYWf5Cb75x/ep9nA5zaBeRFZTW8dlkwcy//ORhzR7SWf60sLcWWMjNkd0xxlKtKGdnfnCiXY8d15ycov/Adt6/7TUFPJSU7rkbxTP1ywe1ocfXX4q//bkSq59+B22HajwpHmlPb8a/dIMVFVTxyX3v8FVUwdz7bThTY4hEUaW6UxfWmg+I2d3nqHEOmtoe7TneDo6a2k8/kbxfs3PTxnEueP68daWg90+bPBoZQ0Q/cu6V059P8bW/ce4Y9Fq7lq8hnlP+2Oajt+9uZWNe44wrKBHk+2Pvv0RZy94he0Hj3tUWT2N3pGE4/UZn9fvH09n3vMSOyNcz9BVwwZPVNfy0GtbeOi1LTz1jTNZv+twhF8vKfzwslO4Yspglq7bw78+XsqxqtqIr9dVdXaVfUcq+cxPXuUfhvXmka9NbfLYrkMVnD3/VS4/bSD3XDEx7u+t0TuStDoza6gf3j+edkW5gK2svII/vfMxU4f3aTLCp6NfeM45lq7bw388t47tByv47KknkZeV1mYn9vkTilhx5wWMuf2FiJ3tidAc0h4//d+NnKiu5Y5/nNDisf49s7lq6mD++M7H3PCZUQzukxPhFbqeQl/Ex6L1UZjBv/95NV+bNow7LzmZqpo6rvvdct7eepDq2vr4bW2kTdMvhyx65WSwdudhxhTl8qfrT+fMUQWN+7b1JZqemhK1zoK89l357aU9h0/w1Ps7uPbMYYzsF3mo7Dc/M4rH3t3O/S9/yPzPf6qbK6yn0BfxsWidwz/63ClMGdqHlFCv3o5PjvPGpgMtzrYbRtpMGdqbX/5tM/1yMykrr2DxijKqGr8cTrDncCWfmzSA+V/4FOmp7e8qjFRneqqx70gl81/cwM3njyGtA6/bnU11RflZPPftGRTlZ7W6z5enDuGZFWUcrawhN7P7I1ihL+JjsV4jMCLKmSnUN7HsPXKCJWt2c/B4FZG6AWvqHMu3fdKhwI9W53fOG837H3/CL17dzPKtB/l/V01u1yiu7rxG4FBFNT2z0xlTlNfmvt85bzQ3zRzjSeCDOnJFJCSWuWJqausYHaX9vaumF3hmRRn//vRq0tNSuO/KSZwztrDN5xyvqmH6va9w8FjL6zvi3TlcUVXLzJ/9jctPG8gtF8Q+ysw5x/GqWnrEKfxj7cjVkE0RAWIbrpoWan+PpKsu3rt00kD+8q3pTS6Ia219gt++sZXJdy+NGPgQ/87hh17bQll5BdPC+jHaUlfn+Pyv3uJ7z6yJay2xUOiLCBD7dQJdcS1FW0b0y2XxjdM5Z2whi0rLmLtwZZMx/Tc9sYJfvroJgNGFuVw1dQgFuZGnn+iZnR63unaWV/DLv23is6eexKdH9I35eSkpxuTBvVhUWsaWfUfjVk8s1LwjIu3m5bUMZ/z4pajzM5XccX6TGpt3DqeaUesc1545jDsuHt+hzuFw33m8lBfW7Oalm89u9xDMfUcqmTH/ZS46pT8/v3JSp+oAjdMXkS7k5bUMsc7PFKlz+Jbzx7B212F++8ZWtuw/xv1XTW73mX/4Fx7AzPGFHRpz3y8vk6+eMYzfvL6FG88dFXWYZ7wp9EUkqbRnfqZIX06XA6MKc/neojVc/otlPBlaoyEWkX49vL5pP4tKyzr0JTjnrBE8+tZHPPrWR9w1++R2P78jFPoiklTiMTHdVVOHMKxvD55fvYveoXmAYmmymh9hXeYT1R1fa6IgN5PH5nyaCf3z2/3cjlLoi0hSifXag7acMbIvZ4ys73z9zetbuPfFDRGvRj5zVF9++/pWVmwvjziPEXRuRNCkUIfu/CUb2FV+osv7SBT6IpJ04t2n8POlHzQGfoOGq5EXj57GI8u2MX5APj0yUiNODteZ4aqLSsu49alVTVaL68qFZjRkU0QC73iUWT53llfQNzeTNT+YxTM3TOM/P3dq3IerLliyscn6zdC1C83EFPpmdqGZbTSzTWY2L8LjN5vZOjNbZWYvmdnQsMdeNLNyM3s2noWLiMRLWxecZaTVR2VXrKPQ3cuTttm8Y2apwAPA+cAO4F0zW+ycWxe2WylQ7Jw7bmbfAOYDV4YeWwDkAF+Pa+UiInHSns7heDctdcVqca2J5Ux/KrDJObfFOVcFPA5cGr6Dc+4V51zDcjBvA4PCHnsJOBKnekVE4s5vq8W1JpaO3IHA9rD7O4DTW9n/OuCF9hRhZnOAOQBDhgxpz1NFROLCqwvO4jUaKVZxHb1jZlcDxcDZ7Xmec+4h4CGon4YhnjWJiCS67vzCiSX0y4DBYfcHhbY1YWYzgduBs51zlfEpT0RE4imWNv13gdFmNtzMMoAvAYvDdzCzycCDwGzn3N74lykiIvHQZug752qAG4ElwHrgCefcWjO728xmh3ZbAOQCT5rZCjNr/FIws9eBJ4HzzGyHmc2K+1GIiEhMYmrTd849DzzfbNv3w27PbOW5MzpcnYiIxJWuyBURCZCEW0TFzPYBH3XiJQqA/XEqJxH47XjAf8fkt+MB/x2T344HWh7TUOdcv7aelHCh31lmVhLL6jHJwm/HA/47Jr8dD/jvmPx2PNDxY1LzjohIgCj0RUQCxI+h/5DXBcSZ344H/HdMfjse8N8x+e14oIPH5Ls2fRERic4n7obVAAADOklEQVSPZ/oiIhKFb0K/rYVekpGZbTOz1aGrnEu8rqe9zOxhM9trZmvCtvUxs6Vm9mHo3729rLG9ohzTXWZWFvqcVpjZZ72ssT3MbLCZvRJaBGmtmX0ntD0pP6dWjieZP6MsM1tuZitDx/SD0PbhZvZOKPP+JzRNTtuv54fmndBCLx8QttALcFWzhV6Sjplto35xmqQcX2xmZwFHgT84504JbZsPHHTO3RP6cu7tnLvVyzrbI8ox3QUcdc79xMvaOsLM+gP9nXPvm1ke8B5wGXAtSfg5tXI8XyR5PyMDejjnjppZOvAG8B3gZuBp59zjZvYrYKVz7pdtvZ5fzvTbXOhFup9z7jXgYLPNlwK/D93+PfX/QyaNKMeUtJxzu5xz74duH6F+fq2BJOnn1MrxJC1X72jobnroHwecCywMbY/5M/JL6Eda6CWpP+gQB/yvmb0XWmjGD4qcc7tCt3cDRV4WE0c3htaIfjhZmkKaM7NhwGTgHXzwOTU7Hkjiz8jMUs1sBbAXWApsBspDE2JCOzLPL6HvV9Odc6cBFwE3hJoWfMPVty0mf/si/BIYCUwCdgE/9bac9jOzXOAp4F+dc4fDH0vGzynC8ST1Z+Scq3XOTaJ+PZOpwLiOvpZfQj+mhV6SjXOuLPTvvcCfqf+wk92eULtrQ/tr0q+/4JzbE/qfsg74NUn2OYXaiZ8C/uicezq0OWk/p0jHk+yfUQPnXDnwCnAG0MvMGmZKjjnz/BL6bS70kmzMrEeoIwoz6wFcAKxp/VlJYTFwTej2NcAzHtYSFw3hGPI5kuhzCnUS/hZY75z7WdhDSfk5RTueJP+M+plZr9DtbOoHrKynPvw/H9ot5s/IF6N3AEJDsO4DUoGHnXP/6XFJnWJmI6g/u4f6dQ/+lGzHZGaPAedQPxvgHuBOYBHwBDCE+tlUv+icS5qO0SjHdA71zQYO2AZ8Paw9PKGZ2XTgdWA1UBfa/O/Ut4Mn3efUyvFcRfJ+RhOp76hNpf5E/Qnn3N2hjHgc6AOUAlfHslStb0JfRETa5pfmHRERiYFCX0QkQBT6IiIBotAXEQkQhb6ISIAo9EVEAkShLyISIAp9EZEA+f/uSU6ptfPlqwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='training loss', linestyle='--', marker='o')\n",
    "plt.plot(history.history['val_loss'], label='validation loss', linestyle='-', marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Categorical cross-entropy')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('../draft_presentation/images/loss.png')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['acc'], label='training accuracy', linestyle='--', marker='o')\n",
    "plt.plot(history.history['val_acc'], label='validation accuracy', linestyle='-', marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('../draft_presentation/images/accuracy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of F1-score, Precision and Recall (micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(metrics_callback.val_f1s_micro, label='f1-score', marker='o', alpha=0.7)\n",
    "plt.plot(metrics_callback.val_precisions_micro, label='precision', marker='D', alpha=0.7)\n",
    "plt.plot(metrics_callback.val_recalls_micro, label='recall', marker='*', alpha=0.7)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Micro-averaged performance')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('../draft_presentation/images/micro.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of F1-score, Precision and Recall (macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(metrics_callback.val_f1s_macro, label='f1-score', marker='o', alpha=0.7)\n",
    "plt.plot(metrics_callback.val_precisions_macro, label='precision', marker='D', alpha=0.7)\n",
    "plt.plot(metrics_callback.val_recalls_macro, label='recall', marker='*', alpha=0.7)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Macro-averaged performance')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('../draft_presentation/images/macro.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of F1-score, Precision and Recall (weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(metrics_callback.val_f1s_weighted, label='f1-score', marker='o', alpha=0.7)\n",
    "plt.plot(metrics_callback.val_precisions_weighted, label='precision', marker='D', alpha=0.7)\n",
    "plt.plot(metrics_callback.val_recalls_weighted, label='recall', marker='*', alpha=0.7)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Weighted-averaged performance')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('../draft_presentation/images/weighted.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "IdSentence|startOffset-endOffset|text|null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def token_spans(txt):\n",
    "    token_offset = []\n",
    "    tokens = nltk.word_tokenize(txt)\n",
    "    offset = 0\n",
    "    for token in tokens:\n",
    "        offset = txt.find(token, offset)\n",
    "        token_offset.append((token, offset, offset+len(token)-1))\n",
    "        offset += len(token)\n",
    "    return tokens, token_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_end_entity_index(labels_list, current_word_index):\n",
    "    end_entity_index = current_word_index\n",
    "    for i in range(current_word_index + 1, len(labels_list)):\n",
    "        if labels_list[i] == 1: # if label == I\n",
    "            end_entity_index += 1\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    return end_entity_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = EnglishStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_with_POS(sentences, pos=True, stem=True):\n",
    "    tokenized_sentences = [word_tokenize(sentence) for sentence in sentences]\n",
    "    tokenized_pos = pos_tag(tokenized_sentences, tagset=None)\n",
    "    \n",
    "    if pos is False and stem is False:\n",
    "        print('original')\n",
    "        return tokenized_sentences\n",
    "    if stem and pos:\n",
    "        print('stem + pos')\n",
    "        tokenized_pos = [ [stemmer.stem(w) + '_' + pos for w, pos in s ] for s in tokenized_pos]\n",
    "    if stem and pos is False:\n",
    "        print('stem')\n",
    "        tokenized_pos = [ [stemmer.stem(w) for w in s ] for s in tokenized_sentences]\n",
    "    else:\n",
    "        print('pos')\n",
    "        tokenized_pos = [ [w + '_' + pos for w, pos in s ] for s in tokenized_pos]\n",
    "    return tokenized_pos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_string = ''\n",
    "vector_size = 20\n",
    "\n",
    "\n",
    "for index, row in sentences_df_test1.iterrows():\n",
    "    sentenceId = row['sentenceID']\n",
    "    sentenceText = row['sentenceText']\n",
    "    # 1. tokenize sentence\n",
    "    tok_sentence, token_offset = token_spans(sentenceText)\n",
    "    # 2. add part of speech\n",
    "    #tok_sentence_pos = [ word + '_' + pos for word, pos in pos_tag(tok_sentence, tagset=None)]\n",
    "    tok_sentence_pos = [ stemmer.stem(word) for word, pos in pos_tag(tok_sentence, tagset=None)]\n",
    "    # 3. get word vectors, predict and write output line\n",
    "    vectors_to_predict = np.array([]).reshape(0, vector_size)\n",
    "    for word in tok_sentence_pos:\n",
    "        vector = word_vectors[word]\n",
    "        vectors_to_predict = np.vstack((vectors_to_predict, vector))\n",
    "    # 4. predict\n",
    "    predictions = model.predict(vectors_to_predict)\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    # 5. generate output\n",
    "    for i in range(len(predicted_labels)):\n",
    "        if predicted_labels[i] == 0:\n",
    "            end_entity_index = find_end_entity_index(predicted_labels, i)\n",
    "            start = token_offset[i][1]\n",
    "            end = token_offset[end_entity_index][2]\n",
    "            output_string += sentenceId + '|' + str(start) + '-' + str(end) + '|' + sentenceText[start:end+1] + '|null\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_file_task_1 = '../results/task9.1_GROUP_1.txt'\n",
    "with open(output_file_task_1, \"w\") as out_file:\n",
    "    out_file.write(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
